{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "bd30b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pymupdf \n",
    "#pip install pdfplumber\n",
    "#pip install pymupdf pillow numpy\n",
    "#pip install paddlepaddle==2.5.2\n",
    "#pip install paddleocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47a1e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF: /home/dataplay/workspace/test_paper.pdf\n",
      "OUT_DIR: /home/dataplay/workspace/result/test_paper\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 입력/출력 경로\n",
    "PDF_PATH = Path(\"./test_paper.pdf\")   # 분석할 PDF\n",
    "OUT_ROOT = Path(\"./result\")\n",
    "DOC_NAME = PDF_PATH.stem\n",
    "OUT_DIR = OUT_ROOT / DOC_NAME         # 문서 루트: ./result/<문서명>\n",
    "\n",
    "# Step-1 산출물(그대로 유지)\n",
    "PAGES_DIR  = OUT_DIR / \"pages\"        # page-level json/txt/png\n",
    "IMAGES_DIR = OUT_DIR / \"images\"       # 추출된 원본 이미지\n",
    "TABLES_DIR = OUT_DIR / \"tables\"       # 추출된 표(CSV/JSON)\n",
    "\n",
    "# ★ 캡션 포함 저장본 폴더(새로 추가)\n",
    "IMAGE_CAP_DIRNAME = \"images_cap\"\n",
    "TABLE_CAP_DIRNAME = \"tables_cap\"\n",
    "IMG_CAP_DIR = OUT_DIR / IMAGE_CAP_DIRNAME\n",
    "TBL_CAP_DIR = OUT_DIR / TABLE_CAP_DIRNAME\n",
    "\n",
    "# Step-1 manifest (Step-2에서 사용)\n",
    "MANIFEST = OUT_DIR / \"manifest.json\"\n",
    "\n",
    "# 디렉토리 생성\n",
    "for d in [OUT_DIR, PAGES_DIR, IMAGES_DIR, TABLES_DIR, IMG_CAP_DIR, TBL_CAP_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PDF:\", PDF_PATH.resolve())\n",
    "print(\"OUT_DIR:\", OUT_DIR.resolve())\n",
    "\n",
    "# --------- OCR 설정 ---------\n",
    "USE_PADDLE = True          # False면 pytesseract 사용\n",
    "OCR_LANG   = \"korean\"      # 'eng', 'korean' 등 문서에 맞게\n",
    "\n",
    "# --------- 매칭 가중치/힌트 ---------\n",
    "W_DIST      = 1000.0   # 거리 가중치(1/d)\n",
    "W_CAPTION_T = 5.0      # 캡션에 term 포함 가중\n",
    "W_OCR_T     = 4.0      # 이미지 OCR에 term 포함 가중\n",
    "W_TABLE_T   = 1.2      # 표 텍스트 가중(이미지보다 약하게)\n",
    "W_BASE_CAP  = 1.0\n",
    "W_BASE_OCR  = 1.0\n",
    "HINTS = [\"figure\",\"fig.\",\"diagram\",\"architecture\",\"table\",\"grid\",\"chart\",\"plot\",\"그림\",\"표\"]\n",
    "\n",
    "MIN_WORD_LEN = 2       # 클릭 대상 최소 길이\n",
    "\n",
    "# --------- 후보 필터/스코어 보정 ---------\n",
    "MIN_IMG_AREA_RATIO = 0.005   # 너무 작은 아이콘 제거(페이지 면적 대비)\n",
    "MAX_IMG_AREA_RATIO = 0.40    # 너무 큰 영역 제거(거의 전체 페이지)\n",
    "PAGE_GAP_PENALTY   = 300.0   # 다른 페이지일 때 감점(페이지 차이 * 값)\n",
    "\n",
    "# --------- 캡션 탐지 관련 설정 ---------\n",
    "CAPTION_SIDE_PAD        = 12   # 이미지/표 좌우 여백\n",
    "CAPTION_BOTTOM_PAD      = 8    # 아래쪽 여백\n",
    "CAPTION_TOP_PAD         = 6    # 위쪽 여백\n",
    "CAPTION_RADIUS_IMG      = 80   # 이미지 아래쪽 캡션 탐지 반경\n",
    "CAPTION_RADIUS_TBL_ABOVE= 50   # 표 위 캡션 탐지 반경\n",
    "CAPTION_RADIUS_TBL_BELOW= 80   # 표 아래 캡션 탐지 반경\n",
    "\n",
    "# --------- “저장본만” 사용(동기화 모드) ---------\n",
    "STRICT_SAME_AS_STEP1 = True                 # 저장된 결과물만 사용\n",
    "ALLOWED_IMAGE_DIRS   = [IMAGE_CAP_DIRNAME]  # 이미지 후보는 images_cap/만\n",
    "ALLOWED_TABLE_DIRS   = [TABLE_CAP_DIRNAME]  # 표 후보는 tables_cap/만\n",
    "\n",
    "# --------- 기타 토글 ---------\n",
    "VFIG_ENABLE = False             # 가상 그림(벡터 도식 자동 추정) 사용 안 함\n",
    "SAVE_CAPTION_COMPOSITE = False  # 캡션 포함 저장본을 생성(이미지/표 둘 다)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "3d41f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, math, re, base64\n",
    "\n",
    "def _to_jsonable(obj):\n",
    "    \"\"\"PDF 추출물 안의 bytes/셋/복합객체를 JSON 직렬화 가능 형태로 변환\"\"\"\n",
    "    if isinstance(obj, bytes):\n",
    "        # 1) UTF-8로 읽히면 텍스트로 저장\n",
    "        try:\n",
    "            return obj.decode(\"utf-8\")\n",
    "        except UnicodeDecodeError:\n",
    "            # 2) 아니면 base64로 안전 저장\n",
    "            return \"base64:\" + base64.b64encode(obj).decode(\"ascii\")\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): _to_jsonable(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [_to_jsonable(v) for v in obj]\n",
    "    if isinstance(obj, set):\n",
    "        return [_to_jsonable(v) for v in obj]\n",
    "    # PyMuPDF Rect 같은 객체가 들어오면 리스트로 변환\n",
    "    if hasattr(obj, \"__dict__\") and obj.__class__.__name__ in (\"Rect\",):\n",
    "        try:\n",
    "            return [float(obj.x0), float(obj.y0), float(obj.x1), float(obj.y1)]\n",
    "        except Exception:\n",
    "            return str(obj)\n",
    "    return obj\n",
    "\n",
    "def save_json(path, obj):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    safe = _to_jsonable(obj)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(safe, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def bbox_center(b):\n",
    "    x0,y0,x1,y1 = b\n",
    "    return ((x0+x1)/2.0, (y0+y1)/2.0)\n",
    "\n",
    "def bbox_distance(b1, b2):\n",
    "    c1 = bbox_center(b1); c2 = bbox_center(b2)\n",
    "    return math.hypot(c1[0]-c2[0], c1[1]-c2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "f37a6278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages parsed: 10\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def parse_pdf(pdf_path: Path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    meta = {\"page_count\": len(doc), \"pages\": []}\n",
    "    for pno in range(len(doc)):\n",
    "        page = doc[pno]\n",
    "        width, height = page.rect.width, page.rect.height\n",
    "\n",
    "        # words: (x0,y0,x1,y1, word, block_no, line_no, word_no)\n",
    "        words = page.get_text(\"words\")\n",
    "        word_items = [{\"text\": w[4], \"bbox\": [w[0], w[1], w[2], w[3]]} for w in words]\n",
    "\n",
    "        # plain text\n",
    "        plain = page.get_text(\"text\")\n",
    "\n",
    "        # blocks (optional, useful for grouping)\n",
    "        blocks_raw = page.get_text(\"blocks\")\n",
    "        block_items = []\n",
    "        for b in blocks_raw:\n",
    "            # (x0, y0, x1, y1, text, block_no, block_type)\n",
    "            x0,y0,x1,y1, text, *rest = b\n",
    "            block_items.append({\"bbox\":[x0,y0,x1,y1], \"text\": text})\n",
    "\n",
    "        # images with bbox via rawdict\n",
    "        raw = page.get_text(\"rawdict\")\n",
    "        image_items = []\n",
    "        def walk(block):\n",
    "            t = block.get(\"type\")\n",
    "            if t == 1:  # image\n",
    "                bbox = block.get(\"bbox\")\n",
    "                xref = block.get(\"image\")\n",
    "                if bbox and xref:\n",
    "                    image_items.append({\"xref\": xref, \"bbox\": bbox})\n",
    "            for k in (\"blocks\",\"lines\",\"spans\"):\n",
    "                if isinstance(block.get(k, []), list):\n",
    "                    for child in block.get(k, []):\n",
    "                        walk(child)\n",
    "        for b in raw.get(\"blocks\", []):\n",
    "            walk(b)\n",
    "\n",
    "        # vector drawings (lines/rects/curves) → 표 라인 등 힌트\n",
    "        drawings = page.get_drawings()  # list of dicts\n",
    "        drawing_count = len(drawings)\n",
    "\n",
    "        # render page to PNG (debug/visual)\n",
    "        pix = page.get_pixmap(matrix=fitz.Matrix(2,2))  # 2x scale\n",
    "        png_path = PAGES_DIR / f\"page_{pno+1:04d}.png\"\n",
    "        pix.save(str(png_path))\n",
    "\n",
    "        # save per-page txt\n",
    "        txt_path = PAGES_DIR / f\"page_{pno+1:04d}.txt\"\n",
    "        with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(plain)\n",
    "\n",
    "        # collect page meta (image paths will be filled after export)\n",
    "        meta[\"pages\"].append({\n",
    "            \"page\": pno,\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            \"words\": word_items,\n",
    "            \"blocks\": block_items,\n",
    "            \"images\": image_items,   # {\"xref\":.., \"bbox\":[..]}\n",
    "            \"drawing_count\": drawing_count,\n",
    "            \"png\": str(png_path)\n",
    "        })\n",
    "    doc.close()\n",
    "    return meta\n",
    "\n",
    "doc_meta = parse_pdf(PDF_PATH)\n",
    "print(\"Pages parsed:\", doc_meta[\"page_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "59811493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported images: 12\n"
     ]
    }
   ],
   "source": [
    "def export_images(pdf_path: Path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    xref_to_path = {}\n",
    "    for pno in range(len(doc)):\n",
    "        page = doc[pno]\n",
    "        for img_info in page.get_images(full=True):\n",
    "            xref = img_info[0]\n",
    "            if xref in xref_to_path:\n",
    "                continue\n",
    "            pix = fitz.Pixmap(doc, xref)\n",
    "            if pix.n >= 5:  # CMYK → RGB\n",
    "                pix = fitz.Pixmap(fitz.csRGB, pix)\n",
    "            img_bytes = pix.tobytes(\"png\")\n",
    "            img_id = \"img_xref_{}\".format(xref)\n",
    "            img_path = IMAGES_DIR / \"{}.png\".format(img_id)\n",
    "            with open(img_path, \"wb\") as f:\n",
    "                f.write(img_bytes)\n",
    "            xref_to_path[xref] = str(img_path)\n",
    "    doc.close()\n",
    "    return xref_to_path\n",
    "\n",
    "xref_to_path = export_images(PDF_PATH)\n",
    "\n",
    "# add image file paths into doc_meta\n",
    "for p in doc_meta[\"pages\"]:\n",
    "    for im in p[\"images\"]:\n",
    "        im[\"path\"] = xref_to_path.get(im[\"xref\"])\n",
    "\n",
    "print(\"Exported images:\", len(xref_to_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "56468d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables extracted (pdfplumber): 7\n"
     ]
    }
   ],
   "source": [
    "## 6) 표 추출 (가능 시 pdfplumber)\n",
    "tables_found = 0\n",
    "try:\n",
    "    import pdfplumber\n",
    "    with pdfplumber.open(str(PDF_PATH)) as pdf:\n",
    "        for pno, page in enumerate(pdf.pages):\n",
    "            # 표 탐지 시도\n",
    "            try:\n",
    "                # find_tables gives table objects with bbox; more informative than extract_tables\n",
    "                tbls = page.find_tables()\n",
    "            except Exception:\n",
    "                tbls = []\n",
    "            if not tbls:\n",
    "                continue\n",
    "            for ti, t in enumerate(tbls, 1):\n",
    "                # CSV 저장\n",
    "                csv_path = TABLES_DIR / \"page_{:04d}_table_{:02d}.csv\".format(pno+1, ti)\n",
    "                try:\n",
    "                    t.to_csv(str(csv_path))\n",
    "                except Exception:\n",
    "                    # fallback: rows as plain list\n",
    "                    data = t.extract()\n",
    "                    import csv\n",
    "                    with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                        writer = csv.writer(f)\n",
    "                        for row in data or []:\n",
    "                            writer.writerow(row or [])\n",
    "                # JSON 저장 (bbox 포함)\n",
    "                tbl_json = {\n",
    "                    \"page\": pno,\n",
    "                    \"bbox\": list(t.bbox) if hasattr(t, \"bbox\") else None,\n",
    "                    \"csv\": str(csv_path)\n",
    "                }\n",
    "                json_path = TABLES_DIR / \"page_{:04d}_table_{:02d}.json\".format(pno+1, ti)\n",
    "                save_json(json_path, tbl_json)\n",
    "                tables_found += 1\n",
    "    print(\"Tables extracted (pdfplumber):\", tables_found)\n",
    "except Exception as e:\n",
    "    print(\"[알림] pdfplumber 사용 불가 또는 표 미검출:\", e)\n",
    "    print(\"- 스캔 PDF의 경우 OCR 후 camelot/tabula 등 추가 도구가 필요할 수 있습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "0c331326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved per-page JSON and manifest:\n",
      "{\n",
      "  \"doc_name\": \"test_paper\",\n",
      "  \"pdf\": \"test_paper.pdf\",\n",
      "  \"out_dir\": \"result/test_paper\",\n",
      "  \"page_count\": 10,\n",
      "  \"pages\": [\n",
      "    {\n",
      "      \"page\": 0,\n",
      "      \"png\": \"result/test_paper/pages/page_0001.png\",\n",
      "      \"json\": \"result/test_paper/pages/page_0001.json\",\n",
      "      \"txt\": \"result/test_paper/pages/page_0001.txt\",\n",
      "      \"words\": 423,\n",
      "      \"images\": 1,\n",
      "      \"drawing_count\": 2,\n",
      "      \"needs_ocr\": false\n",
      "    },\n",
      "    {\n",
      "      \"page\": 1,\n",
      "      \"png\": \"result/test_paper/pages/page_0002.png\",\n",
      "      \"json\": \"result/test_paper/pages/page_0002.json\",\n",
      "      \"txt\": \"result/test_paper/pages/page_0002.txt\",\n",
      "      \"words\": 636,\n",
      "      \"images\": 0,\n",
      "      \"drawing_count\": 2,\n",
      "      \"needs_ocr\": false\n",
      "    },\n",
      "    {\n",
      "      \"page\": 2,\n",
      "      \"png\": \"result/test_paper/pages/page_0003.png\",\n",
      "      \"json\": \"result/test_paper/pages/page_0003.json\",\n",
      "      \"txt\": \"result/test_paper/pages/page_0003.txt\",\n",
      "      \"words\": 434,\n",
      "      \"images\": 2,\n",
      "      \"drawing_count\": 2,\n",
      "      \"needs_ocr\": false\n",
      "    },\n",
      "    {\n",
      "      \"page\": 3,\n",
      "  ...\n"
     ]
    }
   ],
   "source": [
    "## 7) 페이지별 JSON 저장 + manifest.json 생성\n",
    "import json\n",
    "\n",
    "# 페이지 JSON 저장\n",
    "for p in doc_meta[\"pages\"]:\n",
    "    page_json = PAGES_DIR / \"page_{:04d}.json\".format(p[\"page\"]+1)\n",
    "    save_json(page_json, p)\n",
    "\n",
    "# manifest\n",
    "manifest = {\n",
    "    \"doc_name\": DOC_NAME,\n",
    "    \"pdf\": str(PDF_PATH),\n",
    "    \"out_dir\": str(OUT_DIR),\n",
    "    \"page_count\": doc_meta[\"page_count\"],\n",
    "    \"pages\": [],\n",
    "    \"images_total\": sum(len(p[\"images\"]) for p in doc_meta[\"pages\"]),\n",
    "    \"tables_total\": None,  # 아래에서 채움\n",
    "}\n",
    "\n",
    "# needs_ocr flag per page (heuristic: words < 5 or plain text file is near-empty)\n",
    "for p in doc_meta[\"pages\"]:\n",
    "    txt_path = Path(p[\"png\"]).with_suffix(\".txt\")\n",
    "    # 실제 txt 경로는 earlier saved path; compute from known naming\n",
    "    txt_path = PAGES_DIR / \"page_{:04d}.txt\".format(p[\"page\"]+1)\n",
    "    try:\n",
    "        txt_sz = Path(txt_path).stat().st_size\n",
    "    except Exception:\n",
    "        txt_sz = 0\n",
    "    needs_ocr = (len(p[\"words\"]) < 5) or (txt_sz < 10)\n",
    "    manifest[\"pages\"].append({\n",
    "        \"page\": p[\"page\"],\n",
    "        \"png\": p[\"png\"],\n",
    "        \"json\": str(PAGES_DIR / \"page_{:04d}.json\".format(p[\"page\"]+1)),\n",
    "        \"txt\": str(txt_path),\n",
    "        \"words\": len(p[\"words\"]),\n",
    "        \"images\": len(p[\"images\"]),\n",
    "        \"drawing_count\": p[\"drawing_count\"],\n",
    "        \"needs_ocr\": bool(needs_ocr),\n",
    "    })\n",
    "\n",
    "# count tables from folder\n",
    "try:\n",
    "    table_jsons = list(TABLES_DIR.glob(\"*.json\"))\n",
    "    manifest[\"tables_total\"] = len(table_jsons)\n",
    "except Exception:\n",
    "    manifest[\"tables_total\"] = 0\n",
    "\n",
    "save_json(OUT_DIR / \"manifest.json\", manifest)\n",
    "\n",
    "print(\"Saved per-page JSON and manifest:\")\n",
    "print(json.dumps(manifest, ensure_ascii=False, indent=2)[:1000] + \" ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "f1e89c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 7)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, re, os\n",
    "from PIL import Image\n",
    "\n",
    "def load_manifest(manifest_path: Path):\n",
    "    with open(manifest_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        mani = json.load(f)\n",
    "    # 페이지 JSON 로드\n",
    "    pages = []\n",
    "    for p in mani[\"pages\"]:\n",
    "        with open(p[\"json\"], \"r\", encoding=\"utf-8\") as f:\n",
    "            pj = json.load(f)\n",
    "        # png size\n",
    "        png_path = Path(p[\"png\"])\n",
    "        try:\n",
    "            with Image.open(png_path) as im:\n",
    "                png_w, png_h = im.size\n",
    "        except Exception:\n",
    "            png_w = png_h = None\n",
    "        pj[\"_png\"] = {\"path\": str(png_path), \"w\": png_w, \"h\": png_h}\n",
    "        pages.append(pj)\n",
    "    # 테이블 메타\n",
    "    tables = []\n",
    "    tables_dir = manifest_path.parent / \"tables\"\n",
    "    if tables_dir.exists():\n",
    "        for jf in tables_dir.glob(\"*.json\"):\n",
    "            try:\n",
    "                with open(jf, \"r\", encoding=\"utf-8\") as f:\n",
    "                    tj = json.load(f)\n",
    "                tj[\"_json\"] = str(jf)\n",
    "                tables.append(tj)\n",
    "            except Exception:\n",
    "                pass\n",
    "    return mani, pages, tables\n",
    "\n",
    "manifest, pages, tables_meta = load_manifest(MANIFEST)\n",
    "(len(pages), len(tables_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "1544ee1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2244/1979240366.py:5: DeprecationWarning: The parameter `use_angle_cls` has been deprecated and will be removed in the future. Please use `use_textline_orientation` instead.\n",
      "  ocr_engine = PaddleOCR(use_angle_cls=True, lang=OCR_LANG)\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/dataplay/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/dataplay/.paddlex/official_models/UVDoc`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/dataplay/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/dataplay/.paddlex/official_models/PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('korean_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/dataplay/.paddlex/official_models/korean_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR: PaddleOCR loaded\n"
     ]
    }
   ],
   "source": [
    "ocr_engine = None\n",
    "try:\n",
    "    if USE_PADDLE:\n",
    "        from paddleocr import PaddleOCR\n",
    "        ocr_engine = PaddleOCR(use_angle_cls=True, lang=OCR_LANG)\n",
    "        print(\"OCR: PaddleOCR loaded\")\n",
    "    else:\n",
    "        import pytesseract\n",
    "        ocr_engine = pytesseract\n",
    "        print(\"OCR: pytesseract ready (엔진 설치 필요)\")\n",
    "except Exception as e:\n",
    "    print(\"[경고] OCR 엔진 로드 실패:\", e)\n",
    "    print(\"OCR 없이도 매칭은 거리/캡션 기반으로 동작합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "76f13aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def ocr_image(path: str):\n",
    "    if not path or not os.path.exists(path) or ocr_engine is None:\n",
    "        return \"\"\n",
    "    if USE_PADDLE:\n",
    "        res = ocr_engine.ocr(path, cls=True)\n",
    "        texts = []\n",
    "        for line in res[0] if res else []:\n",
    "            txt = line[1][0]\n",
    "            if txt:\n",
    "                texts.append(txt)\n",
    "        return \" \".join(texts)\n",
    "    else:\n",
    "        from PIL import Image\n",
    "        return ocr_engine.image_to_string(Image.open(path))\n",
    "\n",
    "def read_table_text(csv_path: str):\n",
    "    try:\n",
    "        rows = []\n",
    "        with open(csv_path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "            for row in csv.reader(f):\n",
    "                rows.append(\" \".join([c for c in row if c]))\n",
    "        return \" \".join(rows)\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "import re\n",
    "def score_contains(text: str, term: str):\n",
    "    if not text: return 0\n",
    "    try:\n",
    "        return 1 if re.search(r\"\\b\" + re.escape(term) + r\"\\b\", text, flags=re.IGNORECASE) else 0\n",
    "    except re.error:\n",
    "        return (term.lower() in text.lower())*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748e6472",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[258], line 166\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(p\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])):\n\u001b[1;32m    165\u001b[0m     bbox \u001b[38;5;241m=\u001b[39m img[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m\"\u001b[39m]; x0,y0,x1,y1 \u001b[38;5;241m=\u001b[39m bbox\n\u001b[0;32m--> 166\u001b[0m     base \u001b[38;5;241m=\u001b[39m \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    167\u001b[0m     cap_path, cap_text \u001b[38;5;241m=\u001b[39m _save_img_with_caption(p, bbox, base)\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cap_path: \n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/pathlib.py:960\u001b[0m, in \u001b[0;36mPath.__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m Path:\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m WindowsPath \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m PosixPath\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_parts\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flavour\u001b[38;5;241m.\u001b[39mis_supported:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot instantiate \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m on your system\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    963\u001b[0m                               \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/pathlib.py:594\u001b[0m, in \u001b[0;36mPurePath._from_parts\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_from_parts\u001b[39m(\u001b[38;5;28mcls\u001b[39m, args):\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;66;03m# We need to call _parse_args on the instance, so as to get the\u001b[39;00m\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;66;03m# right flavour.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m--> 594\u001b[0m     drv, root, parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drv \u001b[38;5;241m=\u001b[39m drv\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_root \u001b[38;5;241m=\u001b[39m root\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/pathlib.py:578\u001b[0m, in \u001b[0;36mPurePath._parse_args\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    576\u001b[0m     parts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39m_parts\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 578\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;66;03m# Force-cast str subclasses to str (issue #21127)\u001b[39;00m\n\u001b[1;32m    581\u001b[0m         parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(a))\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "## 5) 이미지/표 보조 텍스트 + \"캡션 포함 저장본\" 생성 (virtual_figures 사용 안 함)\n",
    "import os, csv, shutil\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "# 디렉토리 보장\n",
    "IMG_CAP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TBL_CAP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ── 보조 함수들 ────────────────────────────────────────────────────────────────\n",
    "def _union_bbox(ws):\n",
    "    x0 = min(w[\"bbox\"][0] for w in ws); y0 = min(w[\"bbox\"][1] for w in ws)\n",
    "    x1 = max(w[\"bbox\"][2] for w in ws); y1 = max(w[\"bbox\"][3] for w in ws)\n",
    "    return [x0,y0,x1,y1]\n",
    "\n",
    "def _to_png_scale(page):\n",
    "    W, H = page[\"width\"], page[\"height\"]\n",
    "    pm = page.get(\"_png\", {})\n",
    "    pw, ph = pm.get(\"w\"), pm.get(\"h\")\n",
    "    if not (W and H and pw and ph): return None, None\n",
    "    return pw / W, ph / H\n",
    "\n",
    "def _save_fallback_copy(src_path: str | None, dst_dir: Path, base: str):\n",
    "    if not src_path or not isinstance(src_path, (str, os.PathLike)) or not os.path.exists(src_path):\n",
    "        return None\n",
    "    dst = dst_dir / f\"cap_{Path(base).name}\"\n",
    "    try:\n",
    "        shutil.copy2(src_path, dst)\n",
    "        return str(dst)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ── 이미지 저장 ──────────────────────────────────────────────────────────────\n",
    "def _save_img_with_caption(page, img_bbox, basename, orig_img_path: str | None = None):\n",
    "    sx, sy = _to_png_scale(page)\n",
    "    png_path = page.get(\"_png\", {}).get(\"path\")\n",
    "    if not (sx and sy and png_path and os.path.exists(png_path)):\n",
    "        return _save_fallback_copy(orig_img_path, IMG_CAP_DIR, basename), \"\"\n",
    "\n",
    "    W, H = page[\"width\"], page[\"height\"]\n",
    "    x0,y0,x1,y1 = img_bbox\n",
    "\n",
    "    caps = []\n",
    "    for w in page.get(\"words\", []):\n",
    "        wb = w.get(\"bbox\")\n",
    "        if not wb: continue\n",
    "        wy = (wb[1]+wb[3])/2\n",
    "        if wy >= y1 and (wy - y1) <= CAPTION_RADIUS_IMG:\n",
    "            if not (wb[2] < x0 or wb[0] > x1):\n",
    "                caps.append(w)\n",
    "\n",
    "    rx0 = max(0, x0 - CAPTION_SIDE_PAD)\n",
    "    rx1 = min(W, x1 + CAPTION_SIDE_PAD)\n",
    "    if caps:\n",
    "        _, _, _, cy1 = _union_bbox(caps)\n",
    "        ry1 = min(H, max(y1, cy1 + CAPTION_BOTTOM_PAD))\n",
    "    else:\n",
    "        ry1 = y1\n",
    "    ry0 = max(0, y0)\n",
    "\n",
    "    crop_box = (int(rx0*sx), int(ry0*sy), int(rx1*sx), int(ry1*sy))\n",
    "    if crop_box[2]-crop_box[0] <= 8 or crop_box[3]-crop_box[1] <= 8:\n",
    "        return _save_fallback_copy(orig_img_path, IMG_CAP_DIR, basename), \"\"\n",
    "\n",
    "    out_path = IMG_CAP_DIR / f\"cap_{basename}\"\n",
    "    try:\n",
    "        with Image.open(png_path) as im:\n",
    "            im.crop(crop_box).save(out_path)\n",
    "        caption_text = \" \".join(w.get(\"text\",\"\") for w in caps if w.get(\"text\"))\n",
    "        return str(out_path), caption_text\n",
    "    except Exception as e:\n",
    "        print(\"[warn] save_img_with_caption:\", e)\n",
    "        return _save_fallback_copy(orig_img_path, IMG_CAP_DIR, basename), \"\"\n",
    "\n",
    "# ── 표 저장 ────────────────────────────────────────────────────────────────\n",
    "def _save_table_with_caption(page, tbl_bbox, basename):\n",
    "    sx, sy = _to_png_scale(page)\n",
    "    png_path = page.get(\"_png\", {}).get(\"path\")\n",
    "    if not (sx and sy and png_path and os.path.exists(png_path)):\n",
    "        return None, \"\"\n",
    "\n",
    "    W, H = page[\"width\"], page[\"height\"]\n",
    "    x0,y0,x1,y1 = tbl_bbox\n",
    "\n",
    "    above, below = [], []\n",
    "    for w in page.get(\"words\", []):\n",
    "        wb = w.get(\"bbox\")\n",
    "        if not wb: continue\n",
    "        wy = (wb[1]+wb[3])/2\n",
    "        if wy <= y0 and (y0 - wy) <= CAPTION_RADIUS_TBL_ABOVE:\n",
    "            if not (wb[2] < x0 or wb[0] > x1):\n",
    "                above.append(w)\n",
    "        if wy >= y1 and (wy - y1) <= CAPTION_RADIUS_TBL_BELOW:\n",
    "            if not (wb[2] < x0 or wb[0] > x1):\n",
    "                below.append(w)\n",
    "\n",
    "    rx0 = max(0, x0 - CAPTION_SIDE_PAD)\n",
    "    rx1 = min(W, x1 + CAPTION_SIDE_PAD)\n",
    "    ry0 = max(0, y0)\n",
    "    ry1 = min(H, y1)\n",
    "\n",
    "    if above:\n",
    "        _, ay0, _, _ = _union_bbox(above)\n",
    "        ry0 = max(0, min(ry0, ay0 - CAPTION_TOP_PAD))\n",
    "    if below:\n",
    "        _, _, _, by1 = _union_bbox(below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "f2c02d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_cap saved: 11 files\n",
      "tables_cap saved: 7 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2244/1434328717.py:7: DeprecationWarning: Please use `predict` instead.\n",
      "  res = ocr_engine.ocr(path, cls=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _save_img_no_caption(page, img_bbox, basename):\n",
    "    sx, sy = _to_png_scale(page)\n",
    "    png_path = (page.get(\"_png\", {}) or {}).get(\"path\")\n",
    "    if not (sx and sy and png_path and os.path.exists(png_path)):\n",
    "        # 페이지 PNG가 없으면 원본 이미지 파일을 그대로 복사 시도(없으면 None)\n",
    "        return _save_fallback_copy(basename if os.path.exists(basename) else \"\", IMG_CAP_DIR, basename), \"\"\n",
    "\n",
    "    x0,y0,x1,y1 = img_bbox\n",
    "    # 페이지 PNG 좌표로 변환 후 저장 (캡션 확장 X)\n",
    "    crop_box = (int(x0*sx), int(y0*sy), int(x1*sx), int(y1*sy))\n",
    "    if crop_box[2]-crop_box[0] <= 8 or crop_box[3]-crop_box[1] <= 8:\n",
    "        return _save_fallback_copy(\"\", IMG_CAP_DIR, basename), \"\"\n",
    "\n",
    "    out_path = IMG_CAP_DIR / f\"cap_{basename}\"\n",
    "    try:\n",
    "        with Image.open(png_path) as im:\n",
    "            im.crop(crop_box).save(out_path)\n",
    "        return str(out_path), \"\"   # ← 캡션 텍스트 없음\n",
    "    except Exception as e:\n",
    "        print(\"[warn] save_img_no_caption:\", e)\n",
    "        return _save_fallback_copy(\"\", IMG_CAP_DIR, basename), \"\"\n",
    "\n",
    "# ===== 페이지별 이미지 후보 구성 (캡션 여부 토글 반영) =====\n",
    "page_image_aux = {}\n",
    "for p in pages:\n",
    "    W, H = p[\"width\"], p[\"height\"]\n",
    "    area_total = max(1.0, W*H)\n",
    "    cand = []\n",
    "    for idx, img in enumerate(p.get(\"images\", [])):\n",
    "        bbox = img.get(\"bbox\")\n",
    "        if not bbox or len(bbox) != 4:\n",
    "            continue\n",
    "        x0,y0,x1,y1 = bbox\n",
    "\n",
    "        # path None 대비 안전한 파일명\n",
    "        raw_path = img.get(\"path\")\n",
    "        if isinstance(raw_path, str) and raw_path.strip():\n",
    "            base = Path(raw_path).name\n",
    "        else:\n",
    "            base = f\"p{int(p['page']):04d}_img{idx:03d}.png\"\n",
    "\n",
    "        # 토글에 따라 저장 방식 선택\n",
    "\n",
    "        cap_path, cap_text = _save_img_no_caption(p, bbox, base)    # (신규, 캡션 없음)\n",
    "\n",
    "        if not cap_path:\n",
    "            continue\n",
    "\n",
    "        # 크기 필터\n",
    "        ar = (x1-x0)*(y1-y0)/area_total\n",
    "        if ar < MIN_IMG_AREA_RATIO or ar > MAX_IMG_AREA_RATIO:\n",
    "            continue\n",
    "\n",
    "        # OCR(선택)\n",
    "        try:\n",
    "            ocr_text = ocr_image(cap_path) if cap_path else \"\"\n",
    "        except Exception:\n",
    "            ocr_text = \"\"\n",
    "\n",
    "        cand.append({\n",
    "            \"bbox\": bbox,\n",
    "            \"path\": cap_path,\n",
    "            \"caption_text\": cap_text,  # 캡션 비활성화면 \"\", 사용안함\n",
    "            \"ocr_text\": ocr_text\n",
    "        })\n",
    "    page_image_aux[p[\"page\"]] = cand\n",
    "\n",
    "print(\"images_cap saved:\", len(list(IMG_CAP_DIR.glob('*.png'))), \"files\")\n",
    "print(\"tables_cap saved:\", len(list(TBL_CAP_DIR.glob('*.png'))), \"files\")\n",
    "len(page_image_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "27f1a37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6) 매칭 스코어 함수\n",
    "def bbox_center(b):\n",
    "    x0,y0,x1,y1 = b\n",
    "    return ( (x0+x1)/2.0, (y0+y1)/2.0 )\n",
    "\n",
    "def distance_score(word_bbox, target_bbox):\n",
    "    wx, wy = bbox_center(word_bbox)\n",
    "    tx, ty = bbox_center(target_bbox)\n",
    "    d = ((wx-tx)**2 + (wy-ty)**2) ** 0.5 + 1e-6\n",
    "    return W_DIST / d\n",
    "\n",
    "def hint_score(text: str):\n",
    "    if not text: return 0.0\n",
    "    t = text.lower()\n",
    "    return sum(h in t for h in HINTS) * 1.0\n",
    "\n",
    "def total_image_score(term, word_bbox, img_aux):\n",
    "    s = 0.0\n",
    "    s += distance_score(word_bbox, img_aux[\"bbox\"])\n",
    "    s += W_CAPTION_T * score_contains(img_aux.get(\"caption_text\",\"\"), term)\n",
    "    s += W_OCR_T     * score_contains(img_aux.get(\"ocr_text\",\"\"), term)\n",
    "    s += W_BASE_CAP  * hint_score(img_aux.get(\"caption_text\",\"\"))\n",
    "    s += W_BASE_OCR  * hint_score(img_aux.get(\"ocr_text\",\"\"))\n",
    "    return s\n",
    "\n",
    "def total_table_score(term, word_bbox, tbl):\n",
    "    s = 0.0\n",
    "    if tbl.get(\"bbox\"):\n",
    "        s += distance_score(word_bbox, tbl[\"bbox\"])\n",
    "    s += W_TABLE_T * score_contains(tbl.get(\"text\",\"\"), term)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "1e215990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] image candidates: 10 (from ['images_cap'])\n",
      "[info] table candidates: 7 (from ['tables_cap'])\n",
      "Saved index → /home/dataplay/workspace/result/test_paper/linker/index_linker.json\n",
      "pages: 10 | words sampled: 3888\n",
      "[sample] word: 논문 | imgs: 3 | tbls: 3\n"
     ]
    }
   ],
   "source": [
    "## 7) 단어 → top-k(이미지/표) 매칭 인덱스 생성 (모든 페이지 후보 + 캡션 포함 저장본만)\n",
    "import os, math, json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# ── 안전한 기본값/헬퍼 ─────────────────────────────────────────────────────────\n",
    "IMAGE_CAP_DIRNAME = globals().get(\"IMAGE_CAP_DIRNAME\", \"images_cap\")\n",
    "TABLE_CAP_DIRNAME = globals().get(\"TABLE_CAP_DIRNAME\", \"tables_cap\")\n",
    "ALLOWED_IMAGE_DIRS = globals().get(\"ALLOWED_IMAGE_DIRS\", [IMAGE_CAP_DIRNAME])\n",
    "ALLOWED_TABLE_DIRS = globals().get(\"ALLOWED_TABLE_DIRS\", [TABLE_CAP_DIRNAME])\n",
    "\n",
    "def _norm(p): \n",
    "    return (p or \"\").replace(\"\\\\\", \"/\")\n",
    "\n",
    "def _in_allowed_dirs(path_str, dirs):\n",
    "    p = _norm(path_str)\n",
    "    return any(f\"/{d}/\" in p for d in dirs)\n",
    "\n",
    "def _bbox_center(b):\n",
    "    x0,y0,x1,y1 = b\n",
    "    return ((x0+x1)/2.0, (y0+y1)/2.0)\n",
    "\n",
    "def _l2(a,b):\n",
    "    return math.hypot(a[0]-b[0], a[1]-b[1])\n",
    "\n",
    "# 가중치(없으면 기본값)\n",
    "W_DIST      = globals().get(\"W_DIST\", 1000.0)\n",
    "W_CAPTION_T = globals().get(\"W_CAPTION_T\", 5.0)\n",
    "W_OCR_T     = globals().get(\"W_OCR_T\", 4.0)\n",
    "W_TABLE_T   = globals().get(\"W_TABLE_T\", 1.2)\n",
    "W_BASE_CAP  = globals().get(\"W_BASE_CAP\", 1.0)\n",
    "W_BASE_OCR  = globals().get(\"W_BASE_OCR\", 1.0)\n",
    "PAGE_GAP_PENALTY = globals().get(\"PAGE_GAP_PENALTY\", 300.0)\n",
    "HINTS = [h.lower() for h in globals().get(\"HINTS\", [\"figure\",\"fig.\",\"diagram\",\"architecture\",\"table\",\"grid\",\"chart\",\"plot\",\"그림\",\"표\"])]\n",
    "\n",
    "MIN_WORD_LEN = globals().get(\"MIN_WORD_LEN\", 2)\n",
    "TOP_K = globals().get(\"TOP_K\", 3)\n",
    "\n",
    "# Step-5 산출물(필수): page_image_aux, tables_by_page\n",
    "if 'page_image_aux' not in globals():\n",
    "    raise RuntimeError(\"page_image_aux 가 없습니다. Step-5(캡션 포함 저장본 생성)를 먼저 실행하세요.\")\n",
    "if 'tables_by_page' not in globals():\n",
    "    tables_by_page = {}\n",
    "\n",
    "# ── 전 페이지 후보 풀 구성(캡션 저장본만 허용) ─────────────────────────────────────\n",
    "all_imgs = []   # each: {page, bbox, path, caption_text, ocr_text}\n",
    "for pno, items in page_image_aux.items():\n",
    "    for it in items or []:\n",
    "        path = it.get(\"path\")\n",
    "        if not path or not _in_allowed_dirs(path, ALLOWED_IMAGE_DIRS):\n",
    "            continue\n",
    "        all_imgs.append({**it, \"page\": pno})\n",
    "\n",
    "all_tbls = []   # each: {page, bbox, png, csv, text, caption_text}\n",
    "for pno, tlist in tables_by_page.items():\n",
    "    for tb in tlist or []:\n",
    "        png = tb.get(\"png\")\n",
    "        if not png or not _in_allowed_dirs(png, ALLOWED_TABLE_DIRS):\n",
    "            continue\n",
    "        all_tbls.append({**tb, \"page\": pno})\n",
    "\n",
    "print(f\"[info] image candidates: {len(all_imgs)} (from {ALLOWED_IMAGE_DIRS})\")\n",
    "print(f\"[info] table candidates: {len(all_tbls)} (from {ALLOWED_TABLE_DIRS})\")\n",
    "\n",
    "# ── 스코어러(간단/견고 버전) ────────────────────────────────────────────────────\n",
    "def _contains(text, term):\n",
    "    if not text or not term: return False\n",
    "    return term.lower() in text.lower()\n",
    "\n",
    "def _hint_bonus(text):\n",
    "    if not text: return 0.0\n",
    "    t = text.lower()\n",
    "    return sum(1.0 for h in HINTS if h in t) * W_BASE_CAP\n",
    "\n",
    "def image_score(term, word_bbox, wpage, img):\n",
    "    # 거리(같은 페이지일 때만), 다른 페이지는 0에 가까운 점수 + 페널티\n",
    "    s = 0.0\n",
    "    if img.get(\"page\") == wpage and word_bbox and img.get(\"bbox\"):\n",
    "        d = max(1.0, _l2(_bbox_center(word_bbox), _bbox_center(img[\"bbox\"])))\n",
    "        s += W_DIST / d\n",
    "    else:\n",
    "        # 페이지 차이 페널티 (멀수록 감점)\n",
    "        gap = abs((img.get(\"page\") or 0) - (wpage or 0))\n",
    "        s -= PAGE_GAP_PENALTY * gap\n",
    "\n",
    "    # 캡션/ocr에 term 포함\n",
    "    if _contains(img.get(\"caption_text\",\"\"), term):\n",
    "        s += W_CAPTION_T\n",
    "    if _contains(img.get(\"ocr_text\",\"\"), term):\n",
    "        s += W_OCR_T\n",
    "\n",
    "    # 힌트 일반 보너스\n",
    "    s += _hint_bonus(img.get(\"caption_text\",\"\")) + _hint_bonus(img.get(\"ocr_text\",\"\"))\n",
    "    return s\n",
    "\n",
    "def table_score(term, word_bbox, wpage, tb):\n",
    "    s = 0.0\n",
    "    if tb.get(\"page\") == wpage and word_bbox and tb.get(\"bbox\"):\n",
    "        d = max(1.0, _l2(_bbox_center(word_bbox), _bbox_center(tb[\"bbox\"])))\n",
    "        s += W_DIST / d\n",
    "    else:\n",
    "        gap = abs((tb.get(\"page\") or 0) - (wpage or 0))\n",
    "        s -= PAGE_GAP_PENALTY * gap\n",
    "\n",
    "    # 표 텍스트/캡션 텍스트에 term 포함\n",
    "    t_all = (tb.get(\"caption_text\",\"\") + \" \" + tb.get(\"text\",\"\")).strip()\n",
    "    if _contains(t_all, term):\n",
    "        s += W_TABLE_T\n",
    "\n",
    "    s += _hint_bonus(tb.get(\"caption_text\",\"\"))  # 캡션 힌트\n",
    "    return s\n",
    "\n",
    "# ── 인덱스 생성 ────────────────────────────────────────────────────────────────\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LINKER_DIR = OUT_DIR / \"linker\"\n",
    "LINKER_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "manifest = globals().get(\"manifest\", {\"doc_name\": DOC_NAME, \"pdf\": str(PDF_PATH)})\n",
    "\n",
    "index = {\n",
    "    \"doc\": manifest.get(\"doc_name\"),\n",
    "    \"pdf\": manifest.get(\"pdf\"),\n",
    "    \"created\": datetime.utcnow().isoformat()+\"Z\",\n",
    "    \"pages\": [],\n",
    "}\n",
    "\n",
    "for p in pages:\n",
    "    pno = p[\"page\"]\n",
    "    words = [w for w in p.get(\"words\", []) if len(w.get(\"text\",\"\")) >= MIN_WORD_LEN]\n",
    "    page_entry = {\n",
    "        \"page\": pno,\n",
    "        \"png\":  (p.get(\"_png\",{}) or {}).get(\"path\"),\n",
    "        \"png_w\":(p.get(\"_png\",{}) or {}).get(\"w\"),\n",
    "        \"png_h\":(p.get(\"_png\",{}) or {}).get(\"h\"),\n",
    "        \"width\": p.get(\"width\"),\n",
    "        \"height\": p.get(\"height\"),\n",
    "        \"items\": []\n",
    "    }\n",
    "\n",
    "    for w in words:\n",
    "        term = w[\"text\"]\n",
    "        wb = w[\"bbox\"]\n",
    "\n",
    "        # 이미지 후보 스코어링(모든 페이지)\n",
    "        scored_imgs = []\n",
    "        for im in all_imgs:\n",
    "            try:\n",
    "                sc = image_score(term, wb, pno, im)\n",
    "            except Exception:\n",
    "                sc = 0.0\n",
    "            scored_imgs.append((sc, im))\n",
    "        scored_imgs.sort(key=lambda x: x[0], reverse=True)\n",
    "        top_imgs = [\n",
    "            {\"score\": float(s), \"path\": im.get(\"path\"), \"bbox\": im.get(\"bbox\")}\n",
    "            for (s, im) in scored_imgs[:TOP_K]\n",
    "            if im.get(\"path\")\n",
    "        ]\n",
    "\n",
    "        # 표 후보 스코어링(모든 페이지) — ★ png 포함!\n",
    "        scored_tbls = []\n",
    "        for tb in all_tbls:\n",
    "            try:\n",
    "                sc = table_score(term, wb, pno, tb)\n",
    "            except Exception:\n",
    "                sc = 0.0\n",
    "            scored_tbls.append((sc, tb))\n",
    "        scored_tbls.sort(key=lambda x: x[0], reverse=True)\n",
    "        top_tbls = [\n",
    "            {\"score\": float(s), \"png\": tb.get(\"png\"), \"csv\": tb.get(\"csv\"), \"bbox\": tb.get(\"bbox\")}\n",
    "            for (s, tb) in scored_tbls[:TOP_K]\n",
    "            if tb.get(\"png\")  # png가 있는 표만\n",
    "        ]\n",
    "\n",
    "        page_entry[\"items\"].append({\n",
    "            \"word\": term,\n",
    "            \"bbox\": wb,\n",
    "            \"images\": top_imgs,\n",
    "            \"tables\": top_tbls\n",
    "        })\n",
    "\n",
    "    index[\"pages\"].append(page_entry)\n",
    "\n",
    "# 저장\n",
    "INDEX_JSON = LINKER_DIR / \"index_linker.json\"\n",
    "with open(INDEX_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(index, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved index →\", INDEX_JSON.resolve())\n",
    "print(\"pages:\", len(index[\"pages\"]), \n",
    "      \"| words sampled:\", sum(len(p[\"items\"]) for p in index[\"pages\"]))\n",
    "# 간단 검증: 첫 페이지 첫 단어의 후보 개수\n",
    "if index[\"pages\"] and index[\"pages\"][0][\"items\"]:\n",
    "    it0 = index[\"pages\"][0][\"items\"][0]\n",
    "    print(\"[sample] word:\", it0[\"word\"], \n",
    "          \"| imgs:\", len(it0[\"images\"]), \n",
    "          \"| tbls:\", len(it0[\"tables\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "e92e5460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viewer saved → /home/dataplay/workspace/result/test_paper/viewer_overlay.html\n"
     ]
    }
   ],
   "source": [
    "## 8) 오버레이 뷰어 HTML 생성 — 경로를 OUT_DIR 기준 상대경로로 정규화\n",
    "from pathlib import Path\n",
    "import json as _json_mod\n",
    "import json\n",
    "\n",
    "# 필수: CONFIG에서 정의됨\n",
    "HTML_OUT = OUT_DIR / \"viewer_overlay.html\"\n",
    "\n",
    "def to_rel(p: str) -> str | None:\n",
    "    \"\"\"OUT_DIR 기준 상대경로로 변환 (없으면 그대로)\"\"\"\n",
    "    if not p:\n",
    "        return p\n",
    "    try:\n",
    "        abs_p = Path(p).resolve()\n",
    "    except Exception:\n",
    "        p_str = str(p).replace(\"\\\\\", \"/\")\n",
    "        prefix = str(OUT_DIR.resolve()).replace(\"\\\\\", \"/\") + \"/\"\n",
    "        return p_str[len(prefix):] if p_str.startswith(prefix) else p_str\n",
    "\n",
    "    try:\n",
    "        rel = abs_p.relative_to(OUT_DIR.resolve())\n",
    "        return str(rel).replace(\"\\\\\", \"/\")\n",
    "    except Exception:\n",
    "        p_str = str(p).replace(\"\\\\\", \"/\")\n",
    "        prefix = str(OUT_DIR.resolve()).replace(\"\\\\\", \"/\") + \"/\"\n",
    "        return p_str[len(prefix):] if p_str.startswith(prefix) else p_str\n",
    "\n",
    "def normalize_paths(idx: dict) -> dict:\n",
    "    \"\"\"index_linker.json 내 모든 파일 경로를 문서 루트 기준 상대경로로 변경\"\"\"\n",
    "    for pg in idx.get(\"pages\", []):\n",
    "        if pg.get(\"png\"):\n",
    "            pg[\"png\"] = to_rel(pg[\"png\"])\n",
    "        for it in pg.get(\"items\", []):\n",
    "            # 이미지\n",
    "            for im in it.get(\"images\", []):\n",
    "                if im.get(\"path\"):\n",
    "                    im[\"path\"] = to_rel(im[\"path\"])\n",
    "            # 표\n",
    "            for tb in it.get(\"tables\", []):\n",
    "                if tb.get(\"png\"):\n",
    "                    tb[\"png\"] = to_rel(tb[\"png\"])\n",
    "                if tb.get(\"csv\"):\n",
    "                    tb[\"csv\"] = to_rel(tb[\"csv\"])\n",
    "    return idx\n",
    "\n",
    "def _make_overlay_template(index):\n",
    "    html_lines = [\n",
    "\"<!doctype html>\",\n",
    "\"<html>\",\n",
    "\"<head>\",\n",
    "\"  <meta charset='utf-8'/>\",\n",
    "\"  <title>PDF Overlay Viewer</title>\",\n",
    "\"  <style>\",\n",
    "\"    body { margin:0; font-family:system-ui, sans-serif; }\",\n",
    "\"    .wrap { display:flex; height:100vh; }\",\n",
    "\"    .left { width:70%; border-right:1px solid #ddd; padding:12px; box-sizing:border-box; overflow:auto; }\",\n",
    "\"    .right { flex:1; padding:12px; overflow:auto; }\",\n",
    "\"    .canvas { position:relative; background-size:100% 100%; background-repeat:no-repeat; background-position:top left; }\",\n",
    "\"\",\n",
    "\"    /* 버튼 기본: 완전 투명 (배경/보더 없음) */\",\n",
    "\"    .wbtn {\",\n",
    "\"      position:absolute;\",\n",
    "\"      background: transparent;\",\n",
    "\"      border: 1px solid transparent;\",\n",
    "\"      cursor: pointer;\",\n",
    "\"      outline: none;\",\n",
    "\"      -webkit-user-select: none;\",\n",
    "\"      -moz-user-select: none;\",\n",
    "\"      user-select: none;\",\n",
    "\"      -webkit-tap-highlight-color: transparent;\",\n",
    "\"    }\",\n",
    "\"    /* hover 시 얇은 윤곽선만 보이게 */\",\n",
    "\"    .wbtn:hover {\",\n",
    "\"      background: transparent;\",\n",
    "\"      border-color: rgba(0,0,0,0.25);\",\n",
    "\"      box-shadow: 0 0 0 2px rgba(0,0,0,0.06) inset;\",\n",
    "\"    }\",\n",
    "\"\",\n",
    "\"    .placeholder { color:#888; }\",\n",
    "\"    select { padding:6px 8px; }\",\n",
    "\"    .popover{ position:absolute; max-width:45%; background:#fff; border:1px solid #ddd; border-radius:10px;\",\n",
    "\"              box-shadow:0 10px 30px rgba(0,0,0,.15); padding:10px; z-index:10; }\",\n",
    "\"    .popover img{ max-width:100%; height:auto; display:block; }\",\n",
    "\"    .closepop{ position:absolute; top:4px; right:8px; cursor:pointer; opacity:.6; }\",\n",
    "\"  </style>\",\n",
    "\"</head>\",\n",
    "\"<body>\",\n",
    "\"  <div class='wrap'>\",\n",
    "\"    <div class='left'>\",\n",
    "\"      <div style=\\\"display:flex;gap:8px;align-items:center;margin-bottom:8px;\\\">\",\n",
    "\"        <label for=\\\"pageSel\\\">Page:</label>\",\n",
    "\"        <select id=\\\"pageSel\\\"></select>\",\n",
    "\"      </div>\",\n",
    "\"      <div id=\\\"stage\\\"></div>\",\n",
    "\"    </div>\",\n",
    "\"    <div class='right'>\",\n",
    "\"      <h3>Matches</h3>\",\n",
    "\"      <div id='matches' class='cards'><p class='placeholder'>단어를 클릭하세요.</p></div>\",\n",
    "\"    </div>\",\n",
    "\"  </div>\",\n",
    "\"  <script>\",\n",
    "\"    const data = __INDEX_JSON__;\",\n",
    "\"    const stage = document.getElementById('stage');\",\n",
    "\"    const sel = document.getElementById('pageSel');\",\n",
    "\"    const matches = document.getElementById('matches');\",\n",
    "\"    (function(){\",\n",
    "\"      const frag = document.createDocumentFragment();\",\n",
    "\"      for (const p of data.pages) {\",\n",
    "\"        const opt = document.createElement('option');\",\n",
    "\"        opt.value = String(p.page);\",\n",
    "\"        opt.textContent = 'Page ' + (p.page+1);\",\n",
    "\"        frag.appendChild(opt);\",\n",
    "\"      }\",\n",
    "\"      sel.appendChild(frag);\",\n",
    "\"    })();\",\n",
    "\"    function makeOverlayHTML(p){\",\n",
    "\"      if(!(p.png && p.png_w && p.png_h && p.width && p.height)) {\",\n",
    "\"        return '<p class=\\\"placeholder\\\">No PNG available.</p>';\",\n",
    "\"      }\",\n",
    "\"      const sx = p.png_w / p.width; const sy = p.png_h / p.height;\",\n",
    "\"      let btns = '';\",\n",
    "\"      for (const it of p.items) {\",\n",
    "\"        const b = it.bbox;\",\n",
    "\"        const l = Math.max(0, Math.round(b[0]*sx));\",\n",
    "\"        const t = Math.max(0, Math.round(b[1]*sy));\",\n",
    "\"        const w = Math.max(1, Math.round((b[2]-b[0])*sx));\",\n",
    "\"        const h = Math.max(1, Math.round((b[3]-b[1])*sy));\",\n",
    "\"        const payloadStr = JSON.stringify({word: it.word, images: it.images, tables: it.tables})\",\n",
    "\"                           .replaceAll('\\\"','&quot;');\",\n",
    "\"        btns += `<button class=\\\\\\\"wbtn\\\\\\\" style=\\\\\\\"left:${l}px;top:${t}px;width:${w}px;height:${h}px\\\\\\\" data-left=${l} data-top=${t} data-width=${w} data-height=${h} data-payload=\\\\\\\"${payloadStr}\\\\\\\" title=\\\\\\\"${it.word}\\\\\\\"></button>`;\",\n",
    "\"      }\",\n",
    "\"      return `<div class=\\\\\\\"canvas\\\\\\\" id=\\\\\\\"canvas\\\\\\\" style=\\\\\\\"width:${p.png_w}px;height:${p.png_h}px;background-image:url('${p.png}');\\\\\\\">${btns}</div>`;\",\n",
    "\"    }\",\n",
    "\"    function renderPage(pno){\",\n",
    "\"      const p = data.pages.find(x => x.page == pno);\",\n",
    "\"      if(!p){ stage.innerHTML = '<p class=\\\\\\\"placeholder\\\\\\\">No page</p>'; return; }\",\n",
    "\"      stage.innerHTML = makeOverlayHTML(p);\",\n",
    "\"      wireButtons();\",\n",
    "\"      matches.innerHTML = '<p class=\\\"placeholder\\\">단어를 클릭하세요.</p>';\",\n",
    "\"    }\",\n",
    "\"    function closePopover(){ const old = document.querySelector('.popover'); if(old) old.remove(); }\",\n",
    "\"    function showPopover(btn, payload){\",\n",
    "\"      closePopover();\",\n",
    "\"      const canvas = document.getElementById('canvas');\",\n",
    "\"      const pop = document.createElement('div');\",\n",
    "\"      pop.className = 'popover';\",\n",
    "\"      pop.innerHTML = `<div class='closepop' title='close'>&times;</div>`;\",\n",
    "\"      let html = '';\",\n",
    "\"      const im = (payload.images||[]).find(x => x.path);\",\n",
    "\"      if(im){ html += `<img src='${im.path}' alt='match'/>`; }\",\n",
    "\"      else { const tb = (payload.tables||[]).find(x => x.png); if(tb){ html += `<img src='${tb.png}' alt='table'/>`; } else { html += `<div class='placeholder'>연결된 이미지/표 없음</div>`; } }\",\n",
    "\"      pop.insertAdjacentHTML('beforeend', html);\",\n",
    "\"      canvas.appendChild(pop);\",\n",
    "\"      const l = parseInt(btn.dataset.left), t = parseInt(btn.dataset.top), w = parseInt(btn.dataset.width);\",\n",
    "\"      const pad = 8, canvasW = canvas.clientWidth, popW = Math.min(Math.round(canvasW*0.45), 600);\",\n",
    "\"      pop.style.width = popW + 'px';\",\n",
    "\"      let left = l + w + pad; if (left + popW > canvasW) left = Math.max(0, l - popW - pad);\",\n",
    "\"      pop.style.left = left + 'px'; pop.style.top  = t + 'px';\",\n",
    "\"      pop.querySelector('.closepop').addEventListener('click', closePopover);\",\n",
    "\"    }\",\n",
    "\"    function wireButtons(){\",\n",
    "\"      document.querySelectorAll('.wbtn').forEach(btn => {\",\n",
    "\"        btn.addEventListener('click', () => {\",\n",
    "\"          const payload = JSON.parse(btn.dataset.payload.replaceAll('&quot;','\\\\\\\"'));\",\n",
    "\"          const im = (payload.images||[]).find(x => x.path);\",\n",
    "\"          const tb = (payload.tables||[]).find(x => x.png);\",\n",
    "\"          let rightHtml = '';\",\n",
    "\"          if (im) rightHtml = `<div><img src='${im.path}' style='max-width:100%'/></div>`;\",\n",
    "\"          else if (tb) rightHtml = `<div><img src='${tb.png}' style='max-width:100%'/></div>`;\",\n",
    "\"          else rightHtml = `<div class='placeholder'>연결된 이미지/표 없음</div>`;\",\n",
    "\"          matches.innerHTML = rightHtml;\",\n",
    "\"          showPopover(btn, payload);\",\n",
    "\"        });\",\n",
    "\"      });\",\n",
    "\"    }\",\n",
    "\"    sel.addEventListener('change', () => { renderPage(parseInt(sel.value)); });\",\n",
    "\"    renderPage(parseInt(sel.value || 0));\",\n",
    "\"  </script>\",\n",
    "\"</body>\",\n",
    "\"</html>\"\n",
    "    ]\n",
    "    return \"\\n\".join(html_lines)\n",
    "\n",
    "# 인덱스 로드 → 경로 정규화 → HTML 생성\n",
    "INDEX_JSON = OUT_DIR / \"linker\" / \"index_linker.json\"\n",
    "if not INDEX_JSON.exists():\n",
    "    INDEX_JSON = OUT_DIR / \"index_linker.json\"\n",
    "\n",
    "with open(INDEX_JSON, 'r', encoding='utf-8') as f:\n",
    "    _idx_raw = json.load(f)\n",
    "\n",
    "_idx = normalize_paths(_idx_raw)   # ★ 경로 정리\n",
    "\n",
    "_tmpl = _make_overlay_template(_idx)\n",
    "_html = _tmpl.replace('__INDEX_JSON__', _json_mod.dumps(_idx))\n",
    "\n",
    "with open(HTML_OUT, 'w', encoding='utf-8') as f:\n",
    "    f.write(_html)\n",
    "\n",
    "print(\"Viewer saved →\", HTML_OUT.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3b473a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
